{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1004af6a7fbfcd8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# AutoBuild\n",
    "By: [Linxin Song](https://linxins97.github.io/), [Jieyu Zhang](https://jieyuz2.github.io/)\n",
    "Reference: [Agent AutoBuild](https://microsoft.github.io/autogen/blog/2023/11/26/Agent-AutoBuild/)\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "In this notebook, we introduce a new class, `AgentBuilder`, to help user build an automatic task solving process powered by multi-agent system. Specifically, in `build()`, we prompt a LLM to create multiple participant agent and initialize a group chat, and specify whether this task need programming to solve. AgentBuilder also support open-source LLMs by [vLLM](https://docs.vllm.ai/en/latest/index.html) and [Fastchat](https://github.com/lm-sys/FastChat). Check the supported model list [here](https://docs.vllm.ai/en/latest/models/supported_models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78dda8e3826d8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Requirement\n",
    "\n",
    "AutoBuild require `pyautogen[autobuild]`, which can be installed by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9ae50658be975",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install autogen pyautogen[autobuild]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e63ab3604bdb9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1: prepare configuration and some useful functions\n",
    "Prepare a `config_file_or_env` for assistant agent to limit the choice of LLM you want to use in this task. This config can be a path of json file or a name of environment variable. A `default_llm_config` is also required for initialize the specific config of LLMs like seed, temperature, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505f029423b21ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:07:41.225066900Z",
     "start_time": "2024-06-09T15:07:40.443327100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import autogen\n",
    "from autogen.agentchat.contrib.agent_builder import AgentBuilder\n",
    "\n",
    "config_file_or_env = \"/Users/huqianghui/Downloads/1.autogen试验/autoGen/OAI_CONFIG_LIST\"\n",
    "llm_config = {\"temperature\": 0}\n",
    "config_list = autogen.config_list_from_json(config_file_or_env, filter_dict={\"model\": [\"gpt-4\"]})\n",
    "\n",
    "\n",
    "def start_task(execution_task: str, agent_list: list, coding=True):\n",
    "    group_chat = autogen.GroupChat(\n",
    "        agents=agent_list,\n",
    "        messages=[],\n",
    "        max_round=12,\n",
    "        allow_repeat_speaker=agent_list[:-1] if coding is True else agent_list,\n",
    "    )\n",
    "    manager = autogen.GroupChatManager(\n",
    "        groupchat=group_chat,\n",
    "        llm_config={\"config_list\": config_list, **llm_config},\n",
    "    )\n",
    "    agent_list[0].initiate_chat(manager, message=execution_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6586c68fa425b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: create a AgentBuilder\n",
    "Create a `AgentBuilder` with the specified `config_path_or_env`. AgentBuilder will use `gpt-4` in default to complete the whole process, you can specify the `builder_model` and `agent_model` to other OpenAI model to match your task. \n",
    "You can also specify an open-source LLM supporting by vLLM and FastChat, see blog for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa67c771a0fed37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:07:54.256131900Z",
     "start_time": "2024-06-09T15:07:54.236884400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "builder = AgentBuilder(\n",
    "    config_file_or_env=\"/Users/huqianghui/Downloads/1.autogen试验/autoGen/OAI_CONFIG_LIST\", builder_model=[\"gpt-4\"], agent_model=[\"gpt-4\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a655fb6618324",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 3: specify a building task\n",
    "\n",
    "Specify a building task with a general description. Building task will help build manager (a LLM) decide what agents should be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68315f6ec912c58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:07:57.283793900Z",
     "start_time": "2024-06-09T15:07:57.274718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "building_task = \"Generate three agents that I need to translate an English book into Chinese, and I hope the translation is accurate, fluent, and that the punctuation is also converted to Chinese style.There should be no missing words or sentences, and no errors in the text.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5782dd5ecb6c217a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4: build group chat agents\n",
    "Use `build()` to let build manager (the specified `builder_model`) complete the group chat agents generation. If you think coding is necessary in your task, you can use `coding=True` to add a user proxy (an automatic code interpreter) into the agent list, like: \n",
    "```python\n",
    "builder.build(building_task, default_llm_config, coding=True)\n",
    "```\n",
    "If `coding` is not specified, AgentBuilder will determine on its own whether the user proxy should be added or not according to the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab490fdbe46c0473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:08:45.446026500Z",
     "start_time": "2024-06-09T15:07:58.296262400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_list, agent_configs = builder.build(building_task, llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00dd99880a4bf7b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 5: execute task\n",
    "Let agents generated in `build()` to complete the task collaboratively in a group chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.save(\"./agent_list.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a30e4b4297edd1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 6 (Optional): clear all agents and prepare for the next task\n",
    "You can clear all agents generated in this task by the following code if your task is completed or the next task is largely different from the current task. If the agent's backbone is an open-source LLM, this process will also shut down the endpoint server. If necessary, you can use `recycle_endpoint=False` to retain the previous open-source LLMs' endpoint server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0bfff01dd1330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:20.347267900Z",
     "start_time": "2024-06-09T15:11:20.339680600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "builder.clear_all_agents(recycle_endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b88a5d482ceba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:22.539400Z",
     "start_time": "2024-06-09T15:11:22.533316800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved_path = builder.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
