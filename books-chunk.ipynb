{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv langchain langchain-community langchain-openai langchainhub openai tiktoken azure-ai-documentintelligence azure-identity azure-search-documents==11.6.0b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads environment variables using the `dotenv` library and sets the necessary environment variables for Azure services.\n",
    "The environment variables are loaded from the `.env` file in the same directory as this notebook.\n",
    "\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "os.environ[\"AZURE_OPENAI_KEY\"] = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "doc_intelligence_endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "doc_intelligence_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of splits: 18\n"
     ]
    }
   ],
   "source": [
    "book_file_path=\"/Users/huqianghui/Downloads/books-translations/books/TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1.pdf\"\n",
    "\n",
    "# Initiate Azure AI Document Intelligence to load the document. You can either specify file_path or url_path to load the document.\n",
    "loader = AzureAIDocumentIntelligenceLoader(\n",
    "    file_path=book_file_path, \n",
    "    api_key = doc_intelligence_key, \n",
    "    api_endpoint = doc_intelligence_endpoint, \n",
    "    api_model=\"prebuilt-layout\")\n",
    "\n",
    "# analysis_features=[\"ocr_high_resolution\"]\n",
    "# Specify the pages to analyze as an optional parameter\n",
    "# analyze_options = {\n",
    "#     \"pages\": \"10-16\",  # This specifies that only pages 1 through 52 should be analyzed\n",
    "#     \"reading_order\": \"natural\",  # 自然阅读顺序\n",
    "#     \"text_angle\": True,  # 检测文本角度\n",
    "#     \"ocr_high_resolution\": True  # 启用高分辨率OCR\n",
    "# }\n",
    "\n",
    "# Set the analyze options via a method or directly if the load method does not support extra parameters\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the document into chunks base on markdown headers.\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "docs_string = docs[0].page_content\n",
    "splits = text_splitter.split_text(docs_string)\n",
    "\n",
    "print(\"Length of splits: \" + str(len(splits)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-0.md,gpt4-o token:374...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-1.md,gpt4-o token:48...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-2.md,gpt4-o token:2980...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-3.md,gpt4-o token:188...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-4.md,gpt4-o token:490...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-5.md,gpt4-o token:328...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-6.md,gpt4-o token:478...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-7.md,gpt4-o token:456...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-8.md,gpt4-o token:3452...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-9.md,gpt4-o token:211...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-10.md,gpt4-o token:742...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-11.md,gpt4-o token:380...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-12.md,gpt4-o token:894...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-13.md,gpt4-o token:957...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-14.md,gpt4-o token:3477...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-15.md,gpt4-o token:1937...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-16.md,gpt4-o token:1635...\n",
      "file_name:TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1-17.md,gpt4-o token:1711...\n"
     ]
    }
   ],
   "source": [
    "# The base string to split\n",
    "book_name = \"TheInnovatorsDilemmaWhenNewTechnoloClaytonMChristensen-chart1\"\n",
    "\n",
    "# Directory to save the chunks\n",
    "output_dir = \"/Users/huqianghui/Downloads/books-translations/book-chunks\"\n",
    "\n",
    "max_index_length = len(str(len(splits) - 1))\n",
    "\n",
    "for index, document in enumerate(splits):\n",
    "    # Construct the file name\n",
    "    padded_index = f\"{index:0{max_index_length}d}\"\n",
    "    file_name = f\"{book_name}-{padded_index}.md\"\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    \n",
    "    # Write the chunk to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        content = document.page_content.replace(\"Z 转转大师\", \"\")\n",
    "        content = content.replace(\"扫描转换,就是高效\", \"\")\n",
    "        num_tokens_o200k_base = num_tokens_from_string(content)\n",
    "        print(f\"file_name:{file_name},gpt4-o token:{num_tokens_o200k_base}...\")\n",
    "        file.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pymupdf\n",
    "# 打开PDF文件\n",
    "doc = fitz.open(book_file_path)\n",
    "\n",
    "# 遍历每一页\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc.load_page(page_num)\n",
    "    breakpoint()\n",
    "    # 获取页面中的图像信息\n",
    "    images = page.get_images(full=True)\n",
    "    for img_index, img_info in enumerate(images):\n",
    "        xref = img_info[0]  # 图像在PDF中的索引\n",
    "        base_image = doc.extract_image(xref)\n",
    "        pix = pymupdf.Pixmap(doc, xref)\n",
    "        image_bytes = base_image[\"image\"]  # 图像的二进制数据\n",
    "        image_ext = base_image[\"ext\"]  # 图像的文件扩展名，例如 jpg、png 等\n",
    "\n",
    "        # 保存图像到文件\n",
    "        with open(f\"/Users/huqianghui/Downloads/books-translations/book-chunks/images/image_page{page_num + 1}_{img_index}.{image_ext}\", \"wb\") as img_file:\n",
    "            img_file.write(image_bytes)\n",
    "\n",
    "# 关闭PDF文件\n",
    "doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-vision-imageanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping image_page28_1.jpeg: Invalid image size 22x39.\n",
      "Skipping image_page2_1.jpeg: Invalid image size 13x12.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from PIL import Image\n",
    "\n",
    "# Set the values of your computer vision endpoint and computer vision key\n",
    "# as environment variables:\n",
    "try:\n",
    "    endpoint = os.environ[\"AZURE_VISION_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_VISION_KEY\"]\n",
    "except KeyError:\n",
    "    print(\"Missing environment variable 'VISION_ENDPOINT' or 'VISION_KEY'\")\n",
    "    print(\"Set them before running this sample.\")\n",
    "    exit()\n",
    "\n",
    "# Create an Image Analysis client\n",
    "client = ImageAnalysisClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "images_src_folder_path=\"/Users/huqianghui/Downloads/books-translations/book-chunks/images\"\n",
    "images_target_folder_path=\"/Users/huqianghui/Downloads/books-translations/book-chunks/filtered-images\"\n",
    "\n",
    "image_noises=\"扫描转换,就是高效\"\n",
    "\n",
    "for filename in os.listdir(images_src_folder_path):\n",
    "    if filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(images_src_folder_path, filename)\n",
    "        \n",
    "        # 使用Pillow获取图像尺寸\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "        \n",
    "        # 检查图像尺寸是否符合要求\n",
    "        if width < 50 or height < 50 or width > 16000 or height > 16000:\n",
    "            print(f\"Skipping {filename}: Invalid image size {width}x{height}.\")\n",
    "            continue\n",
    "\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "\n",
    "        result = client.analyze(\n",
    "        image_data=image_data,\n",
    "        visual_features=[VisualFeatures.READ])\n",
    "\n",
    "        textInImage = \"\"\n",
    "        if result.read is not None:\n",
    "            for line in result.read.blocks[0].lines:\n",
    "                #print(f\"   Line: '{line.text}', Bounding box {line.bounding_polygon}\")\n",
    "                textInImage += line.text + \"\\n\"\n",
    "        if(not image_noises in textInImage):\n",
    "           shutil.move(image_path, images_target_folder_path) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
